# Job Application Agent ğŸ¤–

A **free, self-hosted** Python agent that automates job applications end-to-end â€” no n8n, no subscriptions, no cloud required.

> Reads from Google Sheets â†’ Applies via browser automation â†’ Logs to SQLite â†’ Notifies via Gmail

---

## Table of Contents

- [How It Works](#how-it-works)
- [Agent Flows](#agent-flows)
  - [Daily Apply Workflow](#daily-apply-workflow)
  - [Status Check Workflow](#status-check-workflow)
- [Architecture](#architecture)
  - [Component Map](#component-map)
  - [Data Flow](#data-flow)
- [Job Status Lifecycle](#job-status-lifecycle)
- [Scheduler Timeline](#scheduler-timeline)
- [Google Sheet Schema](#google-sheet-schema)
- [Configuration Reference](#configuration-reference)
- [CLI Commands](#cli-commands)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Security Notes](#security-notes)

---

## How It Works

At its core the agent runs two recurring workflows on a cron-like schedule â€” equivalent to two n8n workflow tabs running in parallel:

| Workflow | Trigger | What it does |
|---|---|---|
| **Apply** | Weekdays at `APPLY_HOUR:APPLY_MINUTE` UTC | Reads pending jobs â†’ generates cover letters â†’ applies via browser |
| **Status Check** | Every `STATUS_CHECK_INTERVAL_DAYS` days | Re-visits applied jobs â†’ scrapes status â†’ emails you if anything changed |

Everything is driven by a single Google Sheet you maintain. You add job URLs, the agent does the rest.

---

## Agent Flows

### Daily Apply Workflow

This mirrors a typical n8n workflow with a Cron trigger â†’ HTTP/browser nodes â†’ Google Sheets node â†’ Gmail node.

```mermaid
flowchart TD
    TRIGGER(["â° Cron Trigger\nWeekdays @ APPLY_HOUR:APPLY_MINUTE UTC"])
    READ["ğŸ“‹ Read Google Sheet\nFilter: Status = 'Not Applied'"]
    EMPTY{"Any jobs\nfound?"}
    DONE(["âœ… Done â€” nothing to do"])
    BATCH["ğŸ”¢ Slice batch\nâ‰¤ MAX_APPLICATIONS_PER_RUN jobs"]

    LOOP_START(["ğŸ” For each job"])

    COVER["âœï¸ Generate Cover Letter\nJinja2 template\n+ company & position vars"]

    ROUTE{"Job URL\nplatform?"}

    LINKEDIN["ğŸ”µ LinkedIn Easy Apply\nâ‘  Login to LinkedIn\nâ‘¡ Navigate to job URL\nâ‘¢ Click Easy Apply\nâ‘£ Upload resume\nâ‘¤ Fill cover letter\nâ‘¥ Step through form\nâ‘¦ Click Submit"]

    INDEED["ğŸ”´ Indeed Apply\nâ‘  Login to Indeed\nâ‘¡ Navigate to job URL\nâ‘¢ Click Apply Now\nâ‘£ Upload resume\nâ‘¤ Fill cover letter\nâ‘¥ Step through form\nâ‘¦ Click Submit"]

    UNSUPPORTED["âš ï¸ Unsupported Platform\nReturn Failed result\n(apply manually)"]

    SUCCESS{"Application\nsubmitted?"}

    UPDATE_SHEET["ğŸ“Š Update Google Sheet\nStatus â†’ Applied\nApplied_Date, Application_ID, Notes"]
    LOG_DB["ğŸ’¾ Log to SQLite\napplications table"]
    EMAIL["ğŸ“§ Send Gmail Notification\nğŸŸ¢ Green = Applied\nğŸ”´ Red = Failed"]

    NEXT_JOB{{"More jobs\nin batch?"}}
    END(["âœ… Batch complete\nLog summary"])

    TRIGGER --> READ
    READ --> EMPTY
    EMPTY -- "No" --> DONE
    EMPTY -- "Yes" --> BATCH
    BATCH --> LOOP_START
    LOOP_START --> COVER
    COVER --> ROUTE
    ROUTE -- "linkedin.com" --> LINKEDIN
    ROUTE -- "indeed.com" --> INDEED
    ROUTE -- "other" --> UNSUPPORTED
    LINKEDIN --> SUCCESS
    INDEED --> SUCCESS
    UNSUPPORTED --> SUCCESS
    SUCCESS -- "Yes" --> UPDATE_SHEET
    SUCCESS -- "No" --> UPDATE_SHEET
    UPDATE_SHEET --> LOG_DB
    LOG_DB --> EMAIL
    EMAIL --> NEXT_JOB
    NEXT_JOB -- "Yes" --> LOOP_START
    NEXT_JOB -- "No" --> END
```

---

### Status Check Workflow

Runs every N days to detect if recruiters have viewed, rejected, or progressed your applications.

```mermaid
flowchart TD
    TRIGGER2(["â° Interval Trigger\nEvery STATUS_CHECK_INTERVAL_DAYS days\n@ STATUS_CHECK_HOUR UTC"])
    READ2["ğŸ“‹ Read Google Sheet\nFilter: Status = 'Applied'"]
    EMPTY2{"Any applied\njobs?"}
    DONE2(["âœ… Done â€” nothing to check"])

    LOOP2(["ğŸ” For each applied job"])

    PLATFORM{"Job URL\nplatform?"}

    LI_CHECK["ğŸ”µ LinkedIn Status Check\nâ‘  Login to LinkedIn\nâ‘¡ Navigate to Applied Jobs page\nâ‘¢ Find card matching company name\nâ‘£ Scan card text for status keywords"]

    NO_CHECK["âšª No automated check\n(keep current status)"]

    DETECT{"Status\nchanged?"}

    UPDATE_BOTH["ğŸ“Š Update Google Sheet\nStatus column + Last_Checked date"]
    LOG_CHANGE["ğŸ’¾ Log status change\nstatus_changes table"]
    NOTIFY["ğŸ“§ Email Status Update\nğŸŸ¢ Interview Scheduled\nğŸŸ£ Offer Received\nğŸ”´ Rejected\nğŸŸ¡ Under Review"]

    UPDATE_DATE["ğŸ“Š Update Last_Checked only\n(no status change)"]

    NEXT2{{"More jobs\nto check?"}}
    END2(["âœ… Status check complete"])

    TRIGGER2 --> READ2
    READ2 --> EMPTY2
    EMPTY2 -- "No" --> DONE2
    EMPTY2 -- "Yes" --> LOOP2
    LOOP2 --> PLATFORM
    PLATFORM -- "linkedin.com" --> LI_CHECK
    PLATFORM -- "other" --> NO_CHECK
    LI_CHECK --> DETECT
    NO_CHECK --> DETECT
    DETECT -- "Yes" --> UPDATE_BOTH
    DETECT -- "No" --> UPDATE_DATE
    UPDATE_BOTH --> LOG_CHANGE
    LOG_CHANGE --> NOTIFY
    NOTIFY --> NEXT2
    UPDATE_DATE --> NEXT2
    NEXT2 -- "Yes" --> LOOP2
    NEXT2 -- "No" --> END2
```

---

## Architecture

### Component Map

Shows how the 9 source modules depend on each other and what external services each touches.

```mermaid
graph LR
    subgraph CLI["CLI Layer"]
        MAIN["main.py\nEntry point + argparse"]
    end

    subgraph CORE["Orchestration Layer"]
        SCHED["scheduler.py\napply_to_jobs()\ncheck_statuses()"]
    end

    subgraph SERVICES["Service Layer"]
        SHEETS["sheets.py\nGoogle Sheets R/W"]
        GMAIL["gmail_notify.py\nGmail send"]
        BROWSER["browser_apply.py\nPlaywright automation"]
        TRACKER["status_tracker.py\nLinkedIn scraper"]
        COVER["cover_letter.py\nJinja2 templating"]
        DB["database.py\nSQLite history"]
    end

    subgraph INFRA["Infrastructure Layer"]
        AUTH["google_auth.py\nOAuth2 credentials"]
        CONFIG["config.py\n.env loader + validation"]
    end

    subgraph EXTERNAL["External Services"]
        GS[("Google\nSheets API")]
        GAPI[("Gmail\nAPI")]
        LI[("LinkedIn.com\nbrowser")]
        IN[("Indeed.com\nbrowser")]
        SQLITE[("job_history.db\nSQLite")]
    end

    MAIN --> SCHED
    MAIN --> DB
    MAIN --> SHEETS
    MAIN --> GMAIL

    SCHED --> SHEETS
    SCHED --> BROWSER
    SCHED --> TRACKER
    SCHED --> COVER
    SCHED --> DB
    SCHED --> GMAIL

    SHEETS --> AUTH
    GMAIL --> AUTH
    SHEETS --> GS
    GMAIL --> GAPI
    BROWSER --> LI
    BROWSER --> IN
    TRACKER --> LI
    DB --> SQLITE

    AUTH --> CONFIG
    SHEETS --> CONFIG
    GMAIL --> CONFIG
    BROWSER --> CONFIG
    TRACKER --> CONFIG
    COVER --> CONFIG
    DB --> CONFIG
```

---

### Data Flow

End-to-end path of data from your Google Sheet to your Gmail inbox.

```mermaid
sequenceDiagram
    participant Sheet as ğŸ“‹ Google Sheet
    participant Sched as â° Scheduler
    participant Cover as âœï¸ Cover Letter
    participant Browser as ğŸŒ Browser (Playwright)
    participant JobBoard as ğŸ’¼ Job Board
    participant DB as ğŸ’¾ SQLite DB
    participant Gmail as ğŸ“§ Gmail

    Note over Sched: Weekday 9:00 AM UTC trigger

    Sched->>Sheet: read_jobs(status="Not Applied")
    Sheet-->>Sched: [ {Company, Position, Job_URL, ...}, ... ]

    loop For each job (up to MAX_APPLICATIONS_PER_RUN)
        Sched->>Cover: generate(job)
        Cover-->>Sched: "Dear Hiring Manager, ..."

        Sched->>Browser: apply(job, cover_letter)
        Browser->>JobBoard: Login â†’ Navigate â†’ Fill form â†’ Submit
        JobBoard-->>Browser: Success / CAPTCHA / Error
        Browser-->>Sched: { status, application_id, notes, applied_date }

        Sched->>Sheet: mark_applied(job, result)   [batchUpdate â€” 1 API call]
        Sched->>DB: log_application(job, result)
        Sched->>Gmail: send_application_email(job, result)
    end

    Note over Sched: Every 2 days @ 10:00 AM UTC

    Sched->>Sheet: read_jobs(status="Applied")
    Sheet-->>Sched: [ {Company, Status, Application_ID, ...}, ... ]

    loop For each applied job (up to MAX_STATUS_CHECKS_PER_RUN)
        Sched->>Browser: check_job_status(job)
        Browser->>JobBoard: Login â†’ Applied Jobs page â†’ Find card â†’ Read status
        JobBoard-->>Browser: Page HTML
        Browser-->>Sched: { new_status, check_date, notes }

        Sched->>Sheet: mark_status_changed(job, new_status, check_date)

        alt Status changed
            Sched->>DB: log_status_change(job, old, new)
            Sched->>Gmail: send_status_update_email(job, old, new)
        end
    end
```

---

## Job Status Lifecycle

A job moves through these states, driven by agent actions or manual edits.

```mermaid
stateDiagram-v2
    direction LR

    [*] --> NotApplied : You add job to Sheet

    NotApplied --> Applied : Agent submits application\n(apply workflow)
    NotApplied --> Failed : Browser error /\nunsupported platform

    Failed --> NotApplied : You fix URL\nand reset status manually

    Applied --> UnderReview : Status check detects\n"viewed" / "under review"
    Applied --> Rejected : Status check detects\n"rejected"
    Applied --> InterviewScheduled : Status check detects\n"interview" / "assessment"
    Applied --> Withdrawn : You withdraw manually

    UnderReview --> InterviewScheduled : Status check update
    UnderReview --> Rejected : Status check update

    InterviewScheduled --> OfferReceived : Status check detects\n"offer"
    InterviewScheduled --> Rejected : Status check update

    OfferReceived --> [*] : Archive row
    Rejected --> [*] : Archive row
    Withdrawn --> [*] : Archive row

    note right of NotApplied
        Agent reads rows
        with this status
        every weekday
    end note

    note right of Applied
        Agent checks rows
        with this status
        every 2 days
    end note
```

---

## Scheduler Timeline

How the two workflows interleave across a typical work week.

```mermaid
gantt
    title Job Agent â€” Typical Week (UTC)
    dateFormat  YYYY-MM-DD HH:mm
    axisFormat  %a %H:%M

    section Apply Workflow
    Monday apply run        :milestone, m1, 2026-02-23 09:00, 0m
    Tuesday apply run       :milestone, m2, 2026-02-24 09:00, 0m
    Wednesday apply run     :milestone, m3, 2026-02-25 09:00, 0m
    Thursday apply run      :milestone, m4, 2026-02-26 09:00, 0m
    Friday apply run        :milestone, m5, 2026-02-27 09:00, 0m

    section Status Check Workflow
    Status check (day 1)    :milestone, s1, 2026-02-23 10:00, 0m
    Status check (day 3)    :milestone, s2, 2026-02-25 10:00, 0m
    Status check (day 5)    :milestone, s3, 2026-02-27 10:00, 0m

    section You Receive
    Email notifications     :active, e1, 2026-02-23 09:01, 2026-02-27 17:00
```

---

## Google Sheet Schema

The agent reads from and writes to a sheet tab named **`Jobs`** (exact spelling).

```
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  A  â”‚     B     â”‚        C         â”‚        D         â”‚      E      â”‚      F       â”‚          G           â”‚            H             â”‚                 I                  â”‚    J     â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ID  â”‚  Company  â”‚    Position      â”‚     Status       â”‚Applied_Date â”‚ Last_Checked â”‚   Application_ID     â”‚          Notes           â”‚              Job_URL               â”‚ Priority â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 001 â”‚ Acme Corp â”‚ Software Eng.    â”‚ Not Applied      â”‚             â”‚              â”‚                      â”‚                          â”‚ https://linkedin.com/jobs/view/123 â”‚ High     â”‚
â”‚ 002 â”‚ Beta Ltd  â”‚ Product Manager  â”‚ Applied          â”‚ 2026-02-20  â”‚ 2026-02-22   â”‚ AUTO_20260220091532  â”‚ Submitted via Easy Apply â”‚ https://indeed.com/j/abc456        â”‚ Medium   â”‚
â”‚ 003 â”‚ Gamma Inc â”‚ Data Scientist   â”‚ Under Review     â”‚ 2026-02-18  â”‚ 2026-02-22   â”‚ AUTO_20260218091104  â”‚ Status checked via LI    â”‚ https://linkedin.com/jobs/view/789 â”‚ High     â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Column Reference

| Col | Name | Set By | Description |
|-----|------|--------|-------------|
| A | `Job_ID` | You | Unique ID you assign (e.g. `001`, `acme-swe`) |
| B | `Company` | You | Company name â€” used in cover letter and email subject |
| C | `Position` | You | Job title â€” used in cover letter |
| D | `Status` | Agent + You | `Not Applied` â†’ `Applied` â†’ `Under Review` â†’ ... |
| E | `Applied_Date` | Agent | Set automatically when the application is submitted |
| F | `Last_Checked` | Agent | Updated on every status-check pass |
| G | `Application_ID` | Agent | Platform reference ID (e.g. `AUTO_20260220091532`) |
| H | `Notes` | Agent | Auto-filled with apply result or status check notes |
| I | `Job_URL` | You | Full LinkedIn or Indeed job URL |
| J | `Priority` | You | `High` / `Medium` / `Low` â€” informational only |

### Valid Status Values

```
Not Applied  â†’  Applied  â†’  Under Review  â†’  Interview Scheduled  â†’  Offer Received
                                          â†˜                        â†˜
                                           Rejected                 Rejected
                                           Withdrawn
```

---

## Configuration Reference

Copy `.env.example` to `.env` and fill in your values.

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `GOOGLE_SHEET_ID` | âœ… | â€” | Sheet ID from the Google Sheets URL |
| `USER_EMAIL` | âœ… | â€” | Your Gmail address (send + receive notifications) |
| `GOOGLE_CREDENTIALS_PATH` | | `credentials.json` | Path to your OAuth2 credentials file |
| `RESUME_LOCAL_PATH` | âœ… | â€” | Absolute path to your resume PDF |
| `RESUME_URL` | | `""` | Google Drive link to resume (informational) |
| `LINKEDIN_EMAIL` | For LinkedIn | `""` | LinkedIn login email |
| `LINKEDIN_PASSWORD` | For LinkedIn | `""` | LinkedIn password |
| `INDEED_EMAIL` | For Indeed | `""` | Indeed login email |
| `INDEED_PASSWORD` | For Indeed | `""` | Indeed password |
| `APPLY_HOUR` | | `9` | Hour to run apply workflow (UTC, 0â€“23) |
| `APPLY_MINUTE` | | `0` | Minute to run apply workflow (0â€“59) |
| `STATUS_CHECK_INTERVAL_DAYS` | | `2` | Days between status checks (â‰¥ 1) |
| `STATUS_CHECK_HOUR` | | `10` | Hour to run status checks (UTC, 0â€“23) |
| `MAX_APPLICATIONS_PER_RUN` | | `5` | Max jobs applied per daily run |
| `MAX_STATUS_CHECKS_PER_RUN` | | `20` | Max jobs checked per status-check run |
| `DRY_RUN` | | `false` | `true` = log only, never actually apply |

---

## CLI Commands

```
python main.py                    Start the continuous scheduler (normal mode)
python main.py --dry-run          Same, but never submit â€” logs what it would do
python main.py --run-now          Apply to pending jobs right now (skip schedule)
python main.py --check-now        Check all applied job statuses right now
python main.py --test-email       Send a test email to verify Gmail is working
python main.py --list-jobs        Print all pending jobs from the sheet and exit
```

Flags can be combined:
```
python main.py --dry-run --run-now    # safe preview of what apply would do
python main.py --dry-run --check-now  # safe preview of what status check would do
```

---

## Project Structure

```
Job-Agent/
â”‚
â”œâ”€â”€ main.py                    CLI entry point â€” argument parsing + startup
â”œâ”€â”€ scheduler.py               Two workflow functions + APScheduler setup
â”œâ”€â”€ config.py                  All settings loaded from .env, with validation
â”‚
â”œâ”€â”€ sheets.py                  Google Sheets read/write (batchUpdate for atomic writes)
â”œâ”€â”€ gmail_notify.py            Gmail API â€” application + status update emails
â”œâ”€â”€ browser_apply.py           Playwright automation â€” LinkedIn & Indeed apply flows
â”œâ”€â”€ status_tracker.py          LinkedIn Applied Jobs page scraper
â”œâ”€â”€ cover_letter.py            Jinja2 cover letter renderer
â”œâ”€â”€ database.py                SQLite history log (applications + status_changes)
â”œâ”€â”€ google_auth.py             Shared OAuth2 credential loader (used by sheets + gmail)
â”‚
â”œâ”€â”€ cover_letter_template.txt  â† Edit this with your personal cover letter
â”œâ”€â”€ sheet_template.csv         Import into Google Sheets to create the Jobs tab
â”œâ”€â”€ .env.example               Copy to .env and fill in your credentials
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Procfile                   Heroku/Railway worker process definition
â”œâ”€â”€ railway.toml               Railway.app deployment config
â”œâ”€â”€ nixpacks.toml              Build config (Chromium system deps)
â”œâ”€â”€ start.py                   Railway startup â€” writes secrets from env to disk
â”‚
â”œâ”€â”€ SETUP.md                   Step-by-step setup guide
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ conftest.py            Shared fixtures, env stubs, DB isolation
    â”œâ”€â”€ test_cover_letter.py   Cover letter generation tests
    â”œâ”€â”€ test_database.py       SQLite log tests
    â””â”€â”€ test_sheets.py         Google Sheets integration tests (mocked)
```

---

## Quick Start

```bash
# 1. Install
pip install -r requirements.txt
playwright install chromium

# 2. Configure
cp .env.example .env
# Edit .env with your Google Sheet ID, email, resume path, and job board credentials

# 3. First-run auth (opens browser for Google OAuth)
python main.py --list-jobs

# 4. Dry run â€” see what would happen without applying
python main.py --dry-run --run-now

# 5. Start the scheduler
python main.py
```

See **[SETUP.md](SETUP.md)** for the full step-by-step guide including Google Cloud setup.

---

## Local Database

The agent keeps a permanent local history in `job_history.db` (SQLite).

**`applications` table** â€” one row per application attempt:

```
id | job_id | company | position | platform | status | application_id | notes | applied_at | created_at
```

**`status_changes` table** â€” one row per detected status change:

```
id | job_id | company | position | old_status | new_status | changed_at | created_at
```

This gives you a full audit trail even if you modify the Google Sheet manually.

---

## Cover Letter Customisation

Edit `cover_letter_template.txt`. Available Jinja2 variables:

| Variable | Default | Source |
|----------|---------|--------|
| `{{ company }}` | `"the company"` | Sheet: Company column |
| `{{ position }}` | `"the position"` | Sheet: Position column |
| `{{ applicant_name }}` | `"Your Name"` | Set in template or `extra_context` |
| `{{ skills }}` | `"software development"` | Set in template or `extra_context` |

Example template:
```
Dear Hiring Manager at {{ company }},

I am excited to apply for the {{ position }} role. With my background in
{{ skills }}, I am confident I can contribute meaningfully to your team.

Best regards,
{{ applicant_name }}
```

---

## Supported Platforms

| Platform | Apply | Status Check | Notes |
|----------|-------|--------------|-------|
| **LinkedIn** | âœ… Easy Apply | âœ… Applied Jobs page | Non-headless: CAPTCHA can be solved manually |
| **Indeed** | âœ… Indeed Apply | âŒ Not yet implemented | Two-step login handled automatically |
| **Other** | âŒ Skip + log | âŒ N/A | Returns `Failed` result; apply manually |

---

## Security Notes

- `credentials.json`, `.env`, and `token.json` are in `.gitignore` â€” they are never committed
- All Google API calls use OAuth2 with the minimum required scopes (Sheets + Gmail send only)
- The SQLite database (`job_history.db`) stays on your machine
- Passwords are stored only in your local `.env` file; nothing is sent to third parties
- For deployment to Railway/Heroku, credentials are passed as environment variables (not files)

---

## Running Tests

```bash
pytest tests/ -v
```

All 12 tests run without real Google credentials or a browser â€” everything external is mocked.

---

## Deployment (Railway / Heroku)

Set these environment variables in your Railway/Heroku dashboard (instead of `.env`):

- All variables from the [Configuration Reference](#configuration-reference) above
- `GOOGLE_CREDENTIALS_JSON` â€” paste the full contents of `credentials.json`
- `GOOGLE_TOKEN_JSON` â€” paste the full contents of `token.json` (generated on first local run)

The `start.py` script writes these to disk before launching `main.py`.

---

*Built as a free alternative to n8n job automation workflows. No subscriptions, no cloud, no scraping APIs.*
